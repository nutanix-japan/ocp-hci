.. _ocp_csi:

-------------------------------
OCP: Deploy Nutanix CSI for OCP
-------------------------------

In this section we will enable your deployed OCP cluster to have access to Nutanix HCI storage in the form of StorageClass, Physical Volumes and Pysical Volume claims.

We will also install kubernetes operator provided by Nutanix to maintain the lifecycle of operator.

See `What are Kubernetes Operators? <https://docs.openshift.com/container-platform/4.7/operators/understanding/olm-what-operators-are.html>`_ for more information.

OpenShift provides a easy way of implementing these third-party operators via OperatorHub from the cluster manager GUI .

As the Nutanix CSI Operator provides the following capabilities as of now, we will install it to manage all our Nutanix StorageClass in this OCP cluster.

- Basic install
- Seamless upgrades (Manual or Automatic)

In future Nutanix CSI Operator may provide the following additional features:

- Full lifecycle
- Deep insights 
- Autopilot

Install Nutanix CSI Operator
++++++++++++++++++++++++++++

#. Login to you Windows Tools VM using the following credentials;

   - **Username** - administrator@ntnxlab.local
   - **Password** - nutanix/4u

#. Using Chrome browser browse to Console URL you obtained in the previous section. 

   .. code-block:: url
   
    https://console-openshift-console.apps.<initials>1.ntnxlab.local
    
    # example URL
    # https://console-openshift-console.apps.xyz1.ntnxlab.local

#. Use your credentials to Login
   
   - **Username** - kubeadmin
   - **Password** - password from previous section :ref:`ocp_cluster_login`

#. Click on **Log in** (if you are not already logged in)

#. Click on **Operator** > **Operator Hub**

#. You will see all third party operators categorised by solution driven use cases (e.g. Big Data, Database, etc)

   .. figure:: images/ocp_operator_hub.png

   This is in principle similar to Nutanix Calm Marketplace where you can request and install applications.

#. In the **Filter by Keyword** text box, type **Nutanix** to find the Nutanix CSI Operator

#. Click on the **Nutanix CSI Operator**, read basic information about the Operator and click on **Install**

   .. figure:: images/nutanix_csi_operator.png

   Also make sure to check the supported orchestration (RH OCP) platforms

#. In the Operator install wizard choose the following:

   - **Update channel** - stable 
   - **Operator recommended Namespace** - ntnx-system
   - **Update approval** - Automatic (admins usually choose Manual option where control over updates is necessary)

   .. figure:: images/ocp_operator_install_options.png
   
#. Click on **Install** 

#. Once installed you will see the operator in **Operator** > ** Installed Operators** 

You have succesfully installed the Nutanix CSI operator to take care of StorageClass installation and upgrades.

.. note::

 Operators can also be installed using ``oc`` commandline. For more information refer to OCP documentation `here. <https://docs.openshift.com/container-platform/4.7/operators/admin/olm-adding-operators-to-cluster.html#olm-installing-operator-from-operatorhub-using-cli_olm-adding-operators-to-a-cluster>`_

Install StorageClass
++++++++++++++++++++

.. note::

   From now you will be performing commands in **LB_DNS** service/VM's ssh console. 
   
   The lab instructions will have templates for these commands. You will have to change necessary areas to suit your HPOC/SPOC details.

   We suggest doing the following when modifications to commands are required:

   1. Copy the code from lab instructions to notepad/vi/nano or any other favourite text editor
   2. Modify the required fields 
   3. Paste the modified command into the terminal of LB_DNS service through Calm UI
      
      If you are using **Windows PC** the shortcut for pasting into Calm invoked terminal is:

      **Shift + Insert**

      If you are using **Mac** the shortcut for pasting into Calm invoked terminal is:

      **Command + v**


#. In Calm go to your **Applications** > **Openshift ocp1** application

#. Go to the **Services** 

#. Select your **LB_DNS** service

#. Click on **Open Terminal**
   
   .. figure:: images/ocp_lbdns_terminal.png

   The terminal will open in a new browser tab

#. Export the OCP cluster's KUBECONFIG file to environment so we can perform ``oc`` commands

   .. code-block:: bash
      
    export KUBECONFIG=~/openshift/auth/kubeconfig

#. Create a kubernetes secret that the StorageClass can use to access the Nutanix HCI storage

   Copy the following Secret configuration script, modify required fields and execute it in the command line

   **Open a text editor (notepad / vi / nano), paste the contents below and change the fields indicated to suit your environment. Example is also provided**

   **Be sure to use your environment's details for the following fields:**

   - Prism Element IP
   - Prism Element UserName
   - Prism Element Password

   .. code-block:: bash
    :linenos:
    :emphasize-lines: 8

    cat << EOF | oc create -f -
    apiVersion: v1
    kind: Secret
    metadata:
      name: ntnx-secret
      namespace: ntnx-system
    stringData:
      key: <Prism Element IP>:9440:<Prism Element UserName>:<Prism Element Password>    # << change this
      # example: 
      # key: 10.38.2.71:9440:admin:password
    EOF
    
   .. code-block:: bash
   
    # example output here for the above command
    # secret/ntnx-secret created

#. Copy the following StorageClass configuration script, modify required fields and execute it in the command line
    
   **Open a text editor (notepad / vi / nano), paste the contents and change the fields indicated to suit your environment. Example is also provided**

   **Be sure to use your environment's details for the following fields:**

   - Data Services IP and 
   - Storage Container Name

   .. code-block:: bash
    :linenos:
    :emphasize-lines: 15,18

    cat << EOF | oc create -f -
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
        name: nutanix-volume
    provisioner: csi.nutanix.com
    parameters:
      csi.storage.k8s.io/provisioner-secret-name: ntnx-secret
      csi.storage.k8s.io/provisioner-secret-namespace: ntnx-system
      csi.storage.k8s.io/node-publish-secret-name: ntnx-secret
      csi.storage.k8s.io/node-publish-secret-namespace: ntnx-system
      csi.storage.k8s.io/controller-expand-secret-name: ntnx-secret
      csi.storage.k8s.io/controller-expand-secret-namespace: ntnx-system
      csi.storage.k8s.io/fstype: ext4
      dataServiceEndPoint: <Data Services IP>:3260   # << change this
      # example: 
      # dataServiceEndPoint: 10.38.2.72:3260
      storageContainer: <Storage Container Name>     # << change this
      # example: 
      # storageContainer: Default
      storageType: NutanixVolumes
    allowVolumeExpansion: true
    reclaimPolicy: Delete
    EOF

   .. code-block:: bash
   
    # example output here for the above command
    # storageclass.storage.k8s.io/nutanix-volume created
    
#. Make this your default StorageClass

   .. code-block:: bash
    
    oc patch storageclass nutanix-volume -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

#. List your StorageClass
 
   .. code-block:: bash

    oc get StorageClass -A

   .. code-block:: bash

    # example output here for the above command
    # NAME             PROVISIONER       RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
    # nutanix-volume   csi.nutanix.com   Delete          Immediate           true                   45h

#. Create a subscription of the Operator to attach it to ``ntnx-system`` namespace

   .. code-block:: bash

    cat << EOF | oc create -f -
    apiVersion: crd.nutanix.com/v1alpha1
    kind: NutanixCsiStorage
    metadata:
        name: nutanixcsistorage
        namespace: ntnx-system
    spec:
        namespace: ntnx-system
    EOF

   .. code-block:: bash

    # example output here for the above command 
    # nutanixcsistorage.crd.nutanix.com/nutanixcsistorage created
   
We have sucessfully installed Nutanix StorageClass so we can provision Physical Volumes (PV) and Physical Volume Claims (PVC) for the applications we will be deploying in this OCP cluster.






